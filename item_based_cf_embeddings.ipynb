{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "vmziMCU2kCuI"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from scipy.sparse import csr_matrix\n",
        "import pickle\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "VSTqpdJckCuL",
        "outputId": "56536890-6aff-48e9-d177-60a9a690dc9e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WW0ibyGgkCuM"
      },
      "source": [
        "Building the Item Similarity Matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "KTfEwA1gkCuN"
      },
      "outputs": [],
      "source": [
        "def build_item_embeddings(reviews_df, n_factors=50):\n",
        "    # Get unique users and items\n",
        "    unique_users = reviews_df['reviewerID'].unique()\n",
        "    unique_items = reviews_df['asin'].unique()\n",
        "\n",
        "    print(f\"Found {len(unique_users)} users and {len(unique_items)} items\")\n",
        "\n",
        "    # Create mapping dictionaries\n",
        "    user_to_idx = {user: i for i, user in enumerate(unique_users)}\n",
        "    item_to_idx = {item: i for i, item in enumerate(unique_items)}\n",
        "    idx_to_item = {i: item for item, i in item_to_idx.items()}\n",
        "\n",
        "    # Create user-item interaction matrix\n",
        "    user_indices = [user_to_idx[user] for user in reviews_df['reviewerID']]\n",
        "    item_indices = [item_to_idx[item] for item in reviews_df['asin']]\n",
        "    ratings = reviews_df['overall'].values\n",
        "\n",
        "    n_users = len(unique_users)\n",
        "    n_items = len(unique_items)\n",
        "    print(f\"Creating sparse matrix of shape ({n_users}, {n_items})\")\n",
        "\n",
        "    user_item_sparse = csr_matrix((ratings, (user_indices, item_indices)),\n",
        "                                 shape=(n_users, n_items))\n",
        "\n",
        "    print(\"Applying SVD...\")\n",
        "    # Apply SVD to reduce dimensionality\n",
        "    svd = TruncatedSVD(n_components=n_factors, random_state=42)\n",
        "    item_embeddings = svd.fit_transform(user_item_sparse.T)\n",
        "\n",
        "    result = {\n",
        "        'embeddings': item_embeddings,\n",
        "        'item_to_idx': item_to_idx,\n",
        "        'idx_to_item': idx_to_item\n",
        "    }\n",
        "\n",
        "    print(\"Item embeddings created successfully\")\n",
        "    return result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IGQcQUB6kCuN"
      },
      "source": [
        "Saving to Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "LbOfcIzMkCuO"
      },
      "outputs": [],
      "source": [
        "def save_embeddings_to_drive(embeddings_data, file_path):\n",
        "    import os\n",
        "    directory = os.path.dirname(file_path)\n",
        "    if not os.path.exists(directory):\n",
        "        os.makedirs(directory)\n",
        "\n",
        "    print(f\"Saving embeddings to {file_path}...\")\n",
        "    with open(file_path, 'wb') as f:\n",
        "        pickle.dump(embeddings_data, f, protocol=4)\n",
        "\n",
        "    print(\"Embeddings saved successfully to Google Drive\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "UJRd96oJkCuO",
        "outputId": "361411fa-7206-42db-8c24-3711a750c3a3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 192403 users and 63001 items\n",
            "Creating sparse matrix of shape (192403, 63001)\n",
            "Applying SVD...\n",
            "Item embeddings created successfully\n",
            "Saving item embeddings to /content/drive/MyDrive/bt4222data/embeddings/item_embeddings.pkl...\n",
            "Item embeddings saved successfully to Google Drive\n"
          ]
        }
      ],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    import pandas as pd\n",
        "    import pickle\n",
        "    import os\n",
        "\n",
        "    # Load reviews data\n",
        "    reviews_path = \"/content/drive/MyDrive/bt4222data/Reviews Data Cleaned/cleaned_reviews.csv\"\n",
        "    reviews_df = pd.read_csv(reviews_path)\n",
        "\n",
        "    # Build item embeddings instead of similarity matrix\n",
        "    item_embeddings = build_item_embeddings(reviews_df, n_factors=50)\n",
        "\n",
        "    # Save embeddings to drive\n",
        "    embeddings_path = \"/content/drive/MyDrive/bt4222data/embeddings/item_embeddings.pkl\"\n",
        "\n",
        "    # Create directory if it doesn't exist\n",
        "    os.makedirs(os.path.dirname(embeddings_path), exist_ok=True)\n",
        "\n",
        "    # Save to drive\n",
        "    print(f\"Saving item embeddings to {embeddings_path}...\")\n",
        "    with open(embeddings_path, 'wb') as f:\n",
        "        pickle.dump(item_embeddings, f, protocol=4)\n",
        "\n",
        "    print(\"Item embeddings saved successfully to Google Drive\")"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}